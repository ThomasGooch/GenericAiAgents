# ðŸ¤– Agent.AI: Making AI Services Simple

## What is Agent.AI?

**Simple explanation:** Agent.AI provides seamless integration with AI services like OpenAI, Azure OpenAI, and Anthropic, making it easy to add AI capabilities to your agents.

**When to use it:** Every agent that needs to process natural language, generate content, analyze data, or make intelligent decisions needs AI integration.

**Key concepts in plain English:**
- **AI Services** are the external AI providers (OpenAI, Azure OpenAI) that power your intelligent agents
- **Completions** are responses generated by AI models based on your prompts
- **Streaming** allows real-time AI responses as they're generated
- **Configuration** manages API keys, model settings, and provider-specific options

## AI Integration Without the Headaches

### The AI Provider Landscape

```
ðŸŒ AI Provider Comparison:

OpenAI (Direct)
â”œâ”€ âœ… Latest models (GPT-4, GPT-3.5)
â”œâ”€ âœ… Simple setup
â”œâ”€ âœ… Good for experimentation
â”œâ”€ âŒ No enterprise SLA
â”œâ”€ âŒ Data residency concerns
â””â”€ ðŸ’° Pay-per-use pricing

Azure OpenAI
â”œâ”€ âœ… Enterprise SLA & support
â”œâ”€ âœ… Data residency control
â”œâ”€ âœ… Integration with Azure services
â”œâ”€ âœ… Private networking
â”œâ”€ âŒ Model availability lag
â”œâ”€ âŒ More complex setup
â””â”€ ðŸ’° Reserved capacity discounts

Anthropic Claude
â”œâ”€ âœ… Strong safety features
â”œâ”€ âœ… Long context windows
â”œâ”€ âœ… Constitutional AI
â”œâ”€ âŒ Limited availability
â”œâ”€ âŒ Newer ecosystem
â””â”€ ðŸ’° Competitive pricing
```

### When to Choose Which Provider

```csharp
public class AIProviderSelector
{
    public string SelectProvider(BusinessRequirements requirements)
    {
        // Enterprise with compliance needs
        if (requirements.RequiresCompliance || requirements.DataSensitivity == "High")
        {
            return "AzureOpenAI"; // Enterprise features, compliance, data residency
        }

        // High-volume production workloads
        if (requirements.ExpectedVolume > 1000000)
        {
            return "AzureOpenAI"; // Better pricing with reserved capacity
        }

        // Long-form content or complex reasoning
        if (requirements.UseCase.Contains("analysis") || requirements.UseCase.Contains("research"))
        {
            return "Anthropic"; // Superior reasoning capabilities
        }

        // Rapid prototyping or small scale
        if (requirements.Stage == "Prototype" || requirements.ExpectedVolume < 10000)
        {
            return "OpenAI"; // Fastest setup, latest features
        }

        // Default recommendation
        return "AzureOpenAI"; // Best balance of features and enterprise readiness
    }
}

public class BusinessRequirements
{
    public bool RequiresCompliance { get; set; }
    public string DataSensitivity { get; set; } // Low, Medium, High
    public int ExpectedVolume { get; set; }
    public string UseCase { get; set; }
    public string Stage { get; set; } // Prototype, Production, Enterprise
}
```

### Cost Considerations

```csharp
public class AIChampCostCalculator
{
    public decimal EstimateMonthlyCost(string provider, int estimatedTokens, string modelType)
    {
        return provider switch
        {
            "OpenAI" => modelType switch
            {
                "gpt-4" => estimatedTokens * 0.00003m, // $0.03 per 1K tokens
                "gpt-3.5-turbo" => estimatedTokens * 0.000002m, // $0.002 per 1K tokens
                _ => estimatedTokens * 0.00001m
            },
            
            "AzureOpenAI" => modelType switch
            {
                "gpt-4" => estimatedTokens * 0.000025m, // Enterprise discounts
                "gpt-3.5-turbo" => estimatedTokens * 0.0000015m,
                _ => estimatedTokens * 0.000008m
            },
            
            "Anthropic" => modelType switch
            {
                "claude-3-opus" => estimatedTokens * 0.000015m,
                "claude-3-sonnet" => estimatedTokens * 0.000003m,
                _ => estimatedTokens * 0.000005m
            },
            
            _ => estimatedTokens * 0.00001m
        };
    }

    public void ShowCostBreakdown(string useCase, int monthlyRequests)
    {
        var avgTokensPerRequest = EstimateTokensPerRequest(useCase);
        var totalTokens = monthlyRequests * avgTokensPerRequest;

        Console.WriteLine($"Cost Breakdown for {useCase}:");
        Console.WriteLine($"Monthly Requests: {monthlyRequests:N0}");
        Console.WriteLine($"Avg Tokens/Request: {avgTokensPerRequest:N0}");
        Console.WriteLine($"Total Tokens: {totalTokens:N0}");
        Console.WriteLine();

        foreach (var provider in new[] { "OpenAI", "AzureOpenAI", "Anthropic" })
        {
            var cost = EstimateMonthlyCost(provider, totalTokens, "default");
            Console.WriteLine($"{provider}: ${cost:F2}/month");
        }
    }

    private int EstimateTokensPerRequest(string useCase)
    {
        return useCase.ToLower() switch
        {
            "simple-qa" => 100, // Short questions and answers
            "content-generation" => 800, // Blog posts, articles
            "code-review" => 1200, // Code analysis and suggestions
            "data-analysis" => 1500, // Complex data interpretation
            "document-summary" => 2000, // Long document summarization
            _ => 500 // Default estimate
        };
    }
}

// Example usage
var calculator = new AICostCalculator();
calculator.ShowCostBreakdown("content-generation", 10000);
```

## Integration Patterns

### Pattern 1: Direct AI Calls
Simple AI integration for straightforward use cases:

```csharp
using Agent.AI;
using Agent.AI.Models;
using Agent.Core;

public class SimpleAIAgent : BaseAgent
{
    private readonly IAIService _aiService;
    private readonly ILogger<SimpleAIAgent> _logger;

    public SimpleAIAgent(IAIService aiService, ILogger<SimpleAIAgent> logger)
        : base("simple-ai-agent", "Provides AI-powered responses to user queries")
    {
        _aiService = aiService;
        _logger = logger;
    }

    protected override async Task<AgentResult> ExecuteInternalAsync(
        AgentRequest request, 
        CancellationToken cancellationToken)
    {
        try
        {
            _logger.LogInformation("Processing AI request: {Input}", request.Input);

            // Simple prompt construction
            var prompt = $@"
Please provide a helpful and accurate response to the following question:

Question: {request.Input}

Instructions:
- Be concise but thorough
- Use clear, professional language
- If you're uncertain, say so
- Provide actionable information when possible
";

            // Get AI response
            var aiResponse = await _aiService.GetCompletionAsync(prompt, cancellationToken);

            if (!aiResponse.IsSuccess)
            {
                _logger.LogError("AI service failed: {Error}", aiResponse.ErrorMessage);
                return AgentResult.CreateError($"AI processing failed: {aiResponse.ErrorMessage}");
            }

            // Create comprehensive result
            var result = new
            {
                Response = aiResponse.Content,
                Metadata = new
                {
                    TokensUsed = aiResponse.TokensUsed,
                    ModelUsed = aiResponse.ModelUsed,
                    ProcessingTime = aiResponse.Duration.TotalMilliseconds,
                    RequestId = request.Id,
                    ProcessedAt = DateTime.UtcNow
                }
            };

            _logger.LogInformation("AI request completed successfully. Tokens: {Tokens}, Time: {Time}ms", 
                aiResponse.TokensUsed, aiResponse.Duration.TotalMilliseconds);

            return AgentResult.CreateSuccess(System.Text.Json.JsonSerializer.Serialize(result), new Dictionary<string, object>
            {
                ["tokensUsed"] = aiResponse.TokensUsed,
                ["processingTime"] = aiResponse.Duration.TotalMilliseconds,
                ["modelUsed"] = aiResponse.ModelUsed
            });
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error processing AI request");
            return AgentResult.CreateError($"AI processing error: {ex.Message}");
        }
    }
}

// Configuration and usage
public void ConfigureSimpleAI(IServiceCollection services, IConfiguration configuration)
{
    // Configure AI service
    services.Configure<AIConfiguration>(configuration.GetSection("AI"));
    services.AddSingleton<IAIService, SemanticKernelAIService>();

    // Register the agent
    services.AddScoped<SimpleAIAgent>();

    // Initialize AI service
    services.AddHostedService<AIInitializationService>();
}

public class AIInitializationService : IHostedService
{
    private readonly IAIService _aiService;
    private readonly IOptions<AIConfiguration> _config;
    private readonly ILogger<AIInitializationService> _logger;

    public AIInitializationService(
        IAIService aiService, 
        IOptions<AIConfiguration> config,
        ILogger<AIInitializationService> logger)
    {
        _aiService = aiService;
        _config = config;
        _logger = logger;
    }

    public async Task StartAsync(CancellationToken cancellationToken)
    {
        try
        {
            await _aiService.InitializeAsync(_config.Value, cancellationToken);
            
            // Test the connection
            var isHealthy = await _aiService.TestConnectionAsync(cancellationToken);
            if (isHealthy)
            {
                _logger.LogInformation("AI service initialized and tested successfully");
            }
            else
            {
                _logger.LogWarning("AI service initialized but connection test failed");
            }
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to initialize AI service");
            throw;
        }
    }

    public Task StopAsync(CancellationToken cancellationToken) => Task.CompletedTask;
}
```

### Pattern 2: AI with Tool Integration
AI agents that can perform actions through tools:

```csharp
public class ToolEnabledAIAgent : BaseAgent
{
    private readonly IAIService _aiService;
    private readonly IToolRegistry _toolRegistry;
    private readonly ILogger<ToolEnabledAIAgent> _logger;

    public ToolEnabledAIAgent(
        IAIService aiService, 
        IToolRegistry toolRegistry,
        ILogger<ToolEnabledAIAgent> logger)
        : base("tool-enabled-ai-agent", "AI agent that can use tools to perform actions")
    {
        _aiService = aiService;
        _toolRegistry = toolRegistry;
        _logger = logger;
    }

    protected override async Task<AgentResult> ExecuteInternalAsync(
        AgentRequest request, 
        CancellationToken cancellationToken)
    {
        try
        {
            _logger.LogInformation("Processing tool-enabled AI request: {Input}", request.Input);

            // Get available tools
            var availableTools = await _toolRegistry.GetAllToolsAsync(cancellationToken);
            var toolDescriptions = string.Join("\n", availableTools.Select(t => $"- {t.Name}: {t.Description}"));

            // Create tool-aware prompt
            var prompt = $@"
You are an AI assistant with access to the following tools:

{toolDescriptions}

User request: {request.Input}

Instructions:
1. Analyze the user request
2. If tools are needed, specify which tools to use and with what parameters
3. Provide a comprehensive response

If you need to use tools, format your response as JSON:
{{
    ""needsTools"": true,
    ""toolRequests"": [
        {{
            ""toolName"": ""tool-name"",
            ""parameters"": {{
                ""param1"": ""value1"",
                ""param2"": ""value2""
            }},
            ""reasoning"": ""why this tool is needed""
        }}
    ],
    ""expectedOutcome"": ""what you expect to achieve""
}}

If no tools are needed, provide a direct text response.
";

            // Get AI response
            var aiResponse = await _aiService.GetCompletionWithSettingsAsync(
                prompt, 
                maxTokens: 2000, 
                temperature: 0.3, // Lower temperature for more consistent tool usage
                cancellationToken);

            if (!aiResponse.IsSuccess)
            {
                return AgentResult.CreateError($"AI processing failed: {aiResponse.ErrorMessage}");
            }

            // Check if AI wants to use tools
            var toolRequest = TryParseToolRequest(aiResponse.Content);
            if (toolRequest?.NeedsTools == true)
            {
                _logger.LogInformation("AI requested {ToolCount} tools", toolRequest.ToolRequests.Count);
                
                // Execute tools
                var toolResults = await ExecuteToolsAsync(toolRequest.ToolRequests, cancellationToken);
                
                // Get final AI response with tool results
                var finalPrompt = $@"
Original request: {request.Input}

Tool results:
{string.Join("\n\n", toolResults.Select(tr => $"Tool: {tr.ToolName}\nResult: {tr.Result}\nSuccess: {tr.Success}"))}

Please provide a comprehensive response to the user based on the original request and the tool results.
";

                var finalResponse = await _aiService.GetCompletionAsync(finalPrompt, cancellationToken);
                
                return AgentResult.CreateSuccess(finalResponse.Content, new Dictionary<string, object>
                {
                    ["toolsUsed"] = toolRequest.ToolRequests.Select(tr => tr.ToolName).ToArray(),
                    ["toolResults"] = toolResults,
                    ["totalTokensUsed"] = aiResponse.TokensUsed + finalResponse.TokensUsed,
                    ["processingSteps"] = new[] { "analysis", "tool-execution", "synthesis" }
                });
            }
            else
            {
                // Direct response without tools
                _logger.LogInformation("AI provided direct response without tools");
                
                return AgentResult.CreateSuccess(aiResponse.Content, new Dictionary<string, object>
                {
                    ["tokensUsed"] = aiResponse.TokensUsed,
                    ["processingSteps"] = new[] { "direct-response" }
                });
            }
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error in tool-enabled AI processing");
            return AgentResult.CreateError($"Processing error: {ex.Message}");
        }
    }

    private ToolRequestAnalysis? TryParseToolRequest(string aiResponse)
    {
        try
        {
            // Try to parse as JSON
            if (aiResponse.Trim().StartsWith("{"))
            {
                return System.Text.Json.JsonSerializer.Deserialize<ToolRequestAnalysis>(aiResponse);
            }
        }
        catch (Exception ex)
        {
            _logger.LogDebug(ex, "Failed to parse tool request JSON, treating as direct response");
        }

        return new ToolRequestAnalysis { NeedsTools = false };
    }

    private async Task<List<ToolExecutionResult>> ExecuteToolsAsync(
        List<ToolRequest> toolRequests, 
        CancellationToken cancellationToken)
    {
        var results = new List<ToolExecutionResult>();

        foreach (var toolRequest in toolRequests)
        {
            try
            {
                _logger.LogInformation("Executing tool: {ToolName}", toolRequest.ToolName);

                var tool = await _toolRegistry.GetToolAsync(toolRequest.ToolName, cancellationToken);
                if (tool == null)
                {
                    results.Add(new ToolExecutionResult
                    {
                        ToolName = toolRequest.ToolName,
                        Success = false,
                        Result = $"Tool '{toolRequest.ToolName}' not found",
                        ExecutionTime = TimeSpan.Zero
                    });
                    continue;
                }

                var stopwatch = System.Diagnostics.Stopwatch.StartNew();
                var toolResult = await tool.ExecuteAsync(toolRequest.Parameters, cancellationToken);
                stopwatch.Stop();

                results.Add(new ToolExecutionResult
                {
                    ToolName = toolRequest.ToolName,
                    Success = toolResult.IsSuccess,
                    Result = toolResult.IsSuccess ? toolResult.Output?.ToString() ?? "No output" : toolResult.ErrorMessage ?? "Unknown error",
                    ExecutionTime = stopwatch.Elapsed
                });
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Tool execution failed: {ToolName}", toolRequest.ToolName);
                results.Add(new ToolExecutionResult
                {
                    ToolName = toolRequest.ToolName,
                    Success = false,
                    Result = $"Tool execution error: {ex.Message}",
                    ExecutionTime = TimeSpan.Zero
                });
            }
        }

        return results;
    }
}

// Supporting classes
public class ToolRequestAnalysis
{
    public bool NeedsTools { get; set; }
    public List<ToolRequest> ToolRequests { get; set; } = new();
    public string ExpectedOutcome { get; set; } = string.Empty;
}

public class ToolRequest
{
    public string ToolName { get; set; } = string.Empty;
    public Dictionary<string, object> Parameters { get; set; } = new();
    public string Reasoning { get; set; } = string.Empty;
}

public class ToolExecutionResult
{
    public string ToolName { get; set; } = string.Empty;
    public bool Success { get; set; }
    public string Result { get; set; } = string.Empty;
    public TimeSpan ExecutionTime { get; set; }
}
```

### Pattern 3: Complex AI Workflows
Multi-step AI reasoning with context management:

```csharp
public class ComplexReasoningAgent : BaseAgent
{
    private readonly IAIService _aiService;
    private readonly ILogger<ComplexReasoningAgent> _logger;

    public ComplexReasoningAgent(IAIService aiService, ILogger<ComplexReasoningAgent> logger)
        : base("complex-reasoning-agent", "Multi-step AI reasoning for complex problems")
    {
        _aiService = aiService;
        _logger = logger;
    }

    protected override async Task<AgentResult> ExecuteInternalAsync(
        AgentRequest request, 
        CancellationToken cancellationToken)
    {
        var reasoningSteps = new List<ReasoningStep>();
        var context = new ReasoningContext
        {
            OriginalQuery = request.Input,
            AccumulatedKnowledge = new Dictionary<string, object>()
        };

        try
        {
            // Step 1: Problem Analysis
            var analysisStep = await AnalyzeProblemAsync(context, cancellationToken);
            reasoningSteps.Add(analysisStep);
            context.AccumulatedKnowledge["problemAnalysis"] = analysisStep.Output;

            // Step 2: Information Gathering
            var gatheringStep = await GatherInformationAsync(context, cancellationToken);
            reasoningSteps.Add(gatheringStep);
            context.AccumulatedKnowledge["relevantInformation"] = gatheringStep.Output;

            // Step 3: Solution Generation
            var solutionStep = await GenerateSolutionsAsync(context, cancellationToken);
            reasoningSteps.Add(solutionStep);
            context.AccumulatedKnowledge["potentialSolutions"] = solutionStep.Output;

            // Step 4: Solution Evaluation
            var evaluationStep = await EvaluateSolutionsAsync(context, cancellationToken);
            reasoningSteps.Add(evaluationStep);
            context.AccumulatedKnowledge["evaluation"] = evaluationStep.Output;

            // Step 5: Final Synthesis
            var synthesisStep = await SynthesizeFinalAnswerAsync(context, cancellationToken);
            reasoningSteps.Add(synthesisStep);

            // Compile comprehensive result
            var result = new
            {
                FinalAnswer = synthesisStep.Output,
                ReasoningProcess = reasoningSteps.Select(step => new
                {
                    Step = step.StepName,
                    Purpose = step.Purpose,
                    Output = step.Output,
                    TokensUsed = step.TokensUsed,
                    Duration = step.Duration.TotalMilliseconds
                }).ToArray(),
                TotalTokensUsed = reasoningSteps.Sum(s => s.TokensUsed),
                TotalProcessingTime = reasoningSteps.Sum(s => s.Duration.TotalMilliseconds),
                ConfidenceScore = CalculateConfidenceScore(reasoningSteps)
            };

            _logger.LogInformation("Complex reasoning completed with {StepCount} steps, {TotalTokens} tokens", 
                reasoningSteps.Count, result.TotalTokensUsed);

            return AgentResult.CreateSuccess(System.Text.Json.JsonSerializer.Serialize(result), new Dictionary<string, object>
            {
                ["reasoningSteps"] = reasoningSteps.Count,
                ["totalTokens"] = result.TotalTokensUsed,
                ["confidenceScore"] = result.ConfidenceScore
            });
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error in complex reasoning process");
            return AgentResult.CreateError($"Reasoning process failed: {ex.Message}");
        }
    }

    private async Task<ReasoningStep> AnalyzeProblemAsync(ReasoningContext context, CancellationToken cancellationToken)
    {
        var prompt = $@"
Please analyze this problem/question thoroughly:

Query: {context.OriginalQuery}

Provide your analysis in this format:
1. Problem Type: [What kind of problem is this?]
2. Key Components: [What are the main parts of this problem?]
3. Required Information: [What information do we need to solve this?]
4. Complexity Level: [How complex is this problem? Simple/Medium/Complex]
5. Domain Knowledge: [What domain expertise is required?]
";

        return await ExecuteReasoningStep("Problem Analysis", 
            "Understand and categorize the problem", prompt, context, cancellationToken);
    }

    private async Task<ReasoningStep> GatherInformationAsync(ReasoningContext context, CancellationToken cancellationToken)
    {
        var prompt = $@"
Based on the problem analysis, gather relevant information:

Original Query: {context.OriginalQuery}
Problem Analysis: {context.AccumulatedKnowledge["problemAnalysis"]}

Please provide:
1. Relevant Facts: [Key facts related to this problem]
2. Background Context: [Important background information]
3. Related Concepts: [Connected ideas or concepts]
4. Potential Constraints: [Limitations or constraints to consider]
5. Success Criteria: [How to measure a good solution]
";

        return await ExecuteReasoningStep("Information Gathering", 
            "Collect relevant information and context", prompt, context, cancellationToken);
    }

    private async Task<ReasoningStep> GenerateSolutionsAsync(ReasoningContext context, CancellationToken cancellationToken)
    {
        var prompt = $@"
Generate multiple potential solutions:

Original Query: {context.OriginalQuery}
Problem Analysis: {context.AccumulatedKnowledge["problemAnalysis"]}
Relevant Information: {context.AccumulatedKnowledge["relevantInformation"]}

Please provide:
1. Solution A: [First potential solution with brief explanation]
2. Solution B: [Second potential solution with brief explanation] 
3. Solution C: [Third potential solution with brief explanation]
4. Creative Alternative: [An innovative or unconventional approach]
5. Pros/Cons Summary: [Quick pros and cons for each approach]
";

        return await ExecuteReasoningStep("Solution Generation", 
            "Generate multiple potential solutions", prompt, context, cancellationToken);
    }

    private async Task<ReasoningStep> EvaluateSolutionsAsync(ReasoningContext context, CancellationToken cancellationToken)
    {
        var prompt = $@"
Evaluate the potential solutions:

Original Query: {context.OriginalQuery}
Generated Solutions: {context.AccumulatedKnowledge["potentialSolutions"]}

Evaluate each solution on:
1. Feasibility: [How practical is this solution?]
2. Effectiveness: [How well does it solve the problem?]
3. Efficiency: [How resource-efficient is it?]
4. Risk Level: [What are the potential risks?]
5. Implementation Complexity: [How hard is it to implement?]

Provide a ranking and recommendation.
";

        return await ExecuteReasoningStep("Solution Evaluation", 
            "Evaluate and rank potential solutions", prompt, context, cancellationToken);
    }

    private async Task<ReasoningStep> SynthesizeFinalAnswerAsync(ReasoningContext context, CancellationToken cancellationToken)
    {
        var prompt = $@"
Synthesize a final, comprehensive answer:

Original Query: {context.OriginalQuery}
Problem Analysis: {context.AccumulatedKnowledge["problemAnalysis"]}
Information Gathered: {context.AccumulatedKnowledge["relevantInformation"]}
Solutions Generated: {context.AccumulatedKnowledge["potentialSolutions"]}
Solution Evaluation: {context.AccumulatedKnowledge["evaluation"]}

Provide a comprehensive final answer that:
1. Directly addresses the original query
2. Explains your recommended approach
3. Provides actionable steps if applicable
4. Mentions important considerations or caveats
5. Suggests next steps or follow-up actions

Make it clear, actionable, and well-reasoned.
";

        return await ExecuteReasoningStep("Final Synthesis", 
            "Synthesize comprehensive final answer", prompt, context, cancellationToken);
    }

    private async Task<ReasoningStep> ExecuteReasoningStep(
        string stepName, 
        string purpose, 
        string prompt, 
        ReasoningContext context, 
        CancellationToken cancellationToken)
    {
        _logger.LogInformation("Executing reasoning step: {StepName}", stepName);

        var stopwatch = System.Diagnostics.Stopwatch.StartNew();
        var aiResponse = await _aiService.GetCompletionWithSettingsAsync(
            prompt, 
            maxTokens: 1500, 
            temperature: 0.2, // Lower temperature for more consistent reasoning
            cancellationToken);
        stopwatch.Stop();

        if (!aiResponse.IsSuccess)
        {
            throw new InvalidOperationException($"AI failed in step '{stepName}': {aiResponse.ErrorMessage}");
        }

        return new ReasoningStep
        {
            StepName = stepName,
            Purpose = purpose,
            Output = aiResponse.Content,
            TokensUsed = aiResponse.TokensUsed,
            Duration = stopwatch.Elapsed
        };
    }

    private double CalculateConfidenceScore(List<ReasoningStep> reasoningSteps)
    {
        // Simple confidence calculation based on completeness and consistency
        var baseScore = 0.7; // Base confidence
        
        // Bonus for completing all steps
        if (reasoningSteps.Count >= 5) baseScore += 0.1;
        
        // Bonus for detailed outputs
        var avgOutputLength = reasoningSteps.Average(s => s.Output.Length);
        if (avgOutputLength > 500) baseScore += 0.1;
        
        // Cap at 1.0
        return Math.Min(1.0, baseScore);
    }
}

// Supporting classes
public class ReasoningContext
{
    public string OriginalQuery { get; set; } = string.Empty;
    public Dictionary<string, object> AccumulatedKnowledge { get; set; } = new();
}

public class ReasoningStep
{
    public string StepName { get; set; } = string.Empty;
    public string Purpose { get; set; } = string.Empty;
    public string Output { get; set; } = string.Empty;
    public int TokensUsed { get; set; }
    public TimeSpan Duration { get; set; }
}
```

## Production AI Considerations

### Rate Limiting Strategies
Handle API rate limits gracefully:

```csharp
public class RateLimitedAIService : IAIService
{
    private readonly IAIService _baseService;
    private readonly RateLimiter _rateLimiter;
    private readonly ILogger<RateLimitedAIService> _logger;
    private readonly SemaphoreSlim _concurrencyLimiter;

    public RateLimitedAIService(
        IAIService baseService,
        ILogger<RateLimitedAIService> logger,
        AIConfiguration configuration)
    {
        _baseService = baseService;
        _logger = logger;
        
        // Configure rate limiting based on provider
        var limits = GetProviderLimits(configuration.Provider);
        _rateLimiter = new TokenBucketRateLimiter(limits.RequestsPerMinute, limits.TokensPerMinute);
        _concurrencyLimiter = new SemaphoreSlim(limits.MaxConcurrentRequests);
    }

    public async Task<AIResponse> GetCompletionAsync(string prompt, CancellationToken cancellationToken = default)
    {
        await _concurrencyLimiter.WaitAsync(cancellationToken);
        
        try
        {
            // Wait for rate limit availability
            var estimatedTokens = EstimateTokens(prompt);
            await _rateLimiter.WaitForTokensAsync(1, estimatedTokens, cancellationToken);

            _logger.LogDebug("Rate limit acquired for {EstimatedTokens} tokens", estimatedTokens);

            var response = await _baseService.GetCompletionAsync(prompt, cancellationToken);

            // Update rate limiter with actual usage
            if (response.IsSuccess)
            {
                _rateLimiter.ConsumeTokens(1, response.TokensUsed);
            }

            return response;
        }
        catch (RateLimitExceededException ex)
        {
            _logger.LogWarning("Rate limit exceeded, retry after: {RetryAfter}", ex.RetryAfter);
            
            return AIResponse.CreateError(
                $"Rate limit exceeded. Retry after {ex.RetryAfter.TotalSeconds} seconds", 
                TimeSpan.Zero);
        }
        finally
        {
            _concurrencyLimiter.Release();
        }
    }

    private ProviderLimits GetProviderLimits(string provider)
    {
        return provider.ToUpperInvariant() switch
        {
            "OPENAI" => new ProviderLimits
            {
                RequestsPerMinute = 3500,
                TokensPerMinute = 90000,
                MaxConcurrentRequests = 10
            },
            "AZUREOPENAI" => new ProviderLimits
            {
                RequestsPerMinute = 6000, // Higher limits with enterprise
                TokensPerMinute = 150000,
                MaxConcurrentRequests = 20
            },
            "ANTHROPIC" => new ProviderLimits
            {
                RequestsPerMinute = 5000,
                TokensPerMinute = 100000,
                MaxConcurrentRequests = 15
            },
            _ => new ProviderLimits
            {
                RequestsPerMinute = 1000,
                TokensPerMinute = 20000,
                MaxConcurrentRequests = 5
            }
        };
    }

    private int EstimateTokens(string prompt)
    {
        // Rough estimation: 1 token â‰ˆ 4 characters
        return (int)Math.Ceiling(prompt.Length / 4.0) + 100; // Add buffer for response
    }

    // Delegate other methods to base service
    public Task InitializeAsync(AIConfiguration configuration, CancellationToken cancellationToken = default) 
        => _baseService.InitializeAsync(configuration, cancellationToken);
    
    public Task<bool> IsConfiguredAsync(CancellationToken cancellationToken = default) 
        => _baseService.IsConfiguredAsync(cancellationToken);
    
    // ... other delegated methods
}

public class ProviderLimits
{
    public int RequestsPerMinute { get; set; }
    public int TokensPerMinute { get; set; }
    public int MaxConcurrentRequests { get; set; }
}

public class TokenBucketRateLimiter
{
    private readonly int _requestsPerMinute;
    private readonly int _tokensPerMinute;
    private int _availableRequests;
    private int _availableTokens;
    private DateTime _lastRefill = DateTime.UtcNow;
    private readonly object _lock = new object();

    public TokenBucketRateLimiter(int requestsPerMinute, int tokensPerMinute)
    {
        _requestsPerMinute = requestsPerMinute;
        _tokensPerMinute = tokensPerMinute;
        _availableRequests = requestsPerMinute;
        _availableTokens = tokensPerMinute;
    }

    public async Task WaitForTokensAsync(int requests, int tokens, CancellationToken cancellationToken)
    {
        while (true)
        {
            lock (_lock)
            {
                RefillBucket();
                
                if (_availableRequests >= requests && _availableTokens >= tokens)
                {
                    return; // Resources available
                }
            }

            // Wait and try again
            await Task.Delay(1000, cancellationToken);
        }
    }

    public void ConsumeTokens(int requests, int tokens)
    {
        lock (_lock)
        {
            _availableRequests = Math.Max(0, _availableRequests - requests);
            _availableTokens = Math.Max(0, _availableTokens - tokens);
        }
    }

    private void RefillBucket()
    {
        var now = DateTime.UtcNow;
        var elapsedMinutes = (now - _lastRefill).TotalMinutes;
        
        if (elapsedMinutes >= 1.0)
        {
            var refillRequests = (int)(elapsedMinutes * _requestsPerMinute);
            var refillTokens = (int)(elapsedMinutes * _tokensPerMinute);
            
            _availableRequests = Math.Min(_requestsPerMinute, _availableRequests + refillRequests);
            _availableTokens = Math.Min(_tokensPerMinute, _availableTokens + refillTokens);
            
            _lastRefill = now;
        }
    }
}

public class RateLimitExceededException : Exception
{
    public TimeSpan RetryAfter { get; }

    public RateLimitExceededException(TimeSpan retryAfter) 
        : base($"Rate limit exceeded. Retry after {retryAfter.TotalSeconds} seconds")
    {
        RetryAfter = retryAfter;
    }
}
```

### Cost Monitoring
Track and control AI spending:

```csharp
public class CostMonitoringAIService : IAIService
{
    private readonly IAIService _baseService;
    private readonly ICostTracker _costTracker;
    private readonly CostLimits _costLimits;
    private readonly ILogger<CostMonitoringAIService> _logger;

    public CostMonitoringAIService(
        IAIService baseService,
        ICostTracker costTracker,
        CostLimits costLimits,
        ILogger<CostMonitoringAIService> logger)
    {
        _baseService = baseService;
        _costTracker = costTracker;
        _costLimits = costLimits;
        _logger = logger;
    }

    public async Task<AIResponse> GetCompletionAsync(string prompt, CancellationToken cancellationToken = default)
    {
        // Check cost limits before making request
        var currentCost = await _costTracker.GetCurrentCostAsync(DateTime.UtcNow.Date);
        if (currentCost.DailyCost >= _costLimits.DailyLimit)
        {
            _logger.LogWarning("Daily cost limit exceeded: ${DailyCost} >= ${DailyLimit}", 
                currentCost.DailyCost, _costLimits.DailyLimit);
                
            return AIResponse.CreateError(
                $"Daily cost limit exceeded: ${currentCost.DailyCost:F2} >= ${_costLimits.DailyLimit:F2}", 
                TimeSpan.Zero);
        }

        var response = await _baseService.GetCompletionAsync(prompt, cancellationToken);

        // Track cost
        if (response.IsSuccess)
        {
            var cost = CalculateResponseCost(response);
            await _costTracker.RecordCostAsync(new CostRecord
            {
                Timestamp = DateTime.UtcNow,
                Provider = response.ModelUsed,
                TokensUsed = response.TokensUsed,
                Cost = cost,
                RequestType = "completion",
                Metadata = new Dictionary<string, object>
                {
                    ["duration"] = response.Duration.TotalMilliseconds,
                    ["promptLength"] = prompt.Length
                }
            });

            _logger.LogDebug("AI request cost: ${Cost:F4} (Tokens: {Tokens})", cost, response.TokensUsed);
        }

        return response;
    }

    private decimal CalculateResponseCost(AIResponse response)
    {
        // Cost calculation based on provider and model
        return response.ModelUsed.ToLowerInvariant() switch
        {
            var model when model.Contains("gpt-4") => response.TokensUsed * 0.00003m,
            var model when model.Contains("gpt-3.5") => response.TokensUsed * 0.000002m,
            var model when model.Contains("claude") => response.TokensUsed * 0.000008m,
            _ => response.TokensUsed * 0.00001m // Default rate
        };
    }

    // Delegate other methods...
}

public interface ICostTracker
{
    Task<CostSummary> GetCurrentCostAsync(DateTime date);
    Task RecordCostAsync(CostRecord record);
    Task<CostReport> GenerateReportAsync(DateTime startDate, DateTime endDate);
}

public class CostSummary
{
    public decimal DailyCost { get; set; }
    public decimal MonthlyCost { get; set; }
    public int TotalRequests { get; set; }
    public int TotalTokens { get; set; }
}

public class CostRecord
{
    public DateTime Timestamp { get; set; }
    public string Provider { get; set; } = string.Empty;
    public int TokensUsed { get; set; }
    public decimal Cost { get; set; }
    public string RequestType { get; set; } = string.Empty;
    public Dictionary<string, object> Metadata { get; set; } = new();
}

public class CostLimits
{
    public decimal DailyLimit { get; set; } = 100m; // $100/day default
    public decimal MonthlyLimit { get; set; } = 2000m; // $2000/month default
    public decimal AlertThreshold { get; set; } = 0.8m; // Alert at 80% of limit
}
```

### Quality Assurance
Ensure consistent AI output quality:

```csharp
public class QualityAssuredAIService : IAIService
{
    private readonly IAIService _baseService;
    private readonly IQualityValidator _qualityValidator;
    private readonly ILogger<QualityAssuredAIService> _logger;
    private readonly QualitySettings _settings;

    public QualityAssuredAIService(
        IAIService baseService,
        IQualityValidator qualityValidator,
        QualitySettings settings,
        ILogger<QualityAssuredAIService> logger)
    {
        _baseService = baseService;
        _qualityValidator = qualityValidator;
        _settings = settings;
        _logger = logger;
    }

    public async Task<AIResponse> GetCompletionAsync(string prompt, CancellationToken cancellationToken = default)
    {
        var attempts = 0;
        var maxAttempts = _settings.MaxRetryAttempts;

        while (attempts < maxAttempts)
        {
            attempts++;
            
            var response = await _baseService.GetCompletionAsync(prompt, cancellationToken);
            
            if (!response.IsSuccess)
            {
                return response; // Return AI service errors immediately
            }

            // Validate response quality
            var qualityResult = await _qualityValidator.ValidateAsync(new QualityValidationRequest
            {
                Prompt = prompt,
                Response = response.Content,
                Context = new Dictionary<string, object>
                {
                    ["model"] = response.ModelUsed,
                    ["tokens"] = response.TokensUsed,
                    ["attempt"] = attempts
                }
            });

            if (qualityResult.IsAcceptable)
            {
                _logger.LogDebug("AI response passed quality validation on attempt {Attempt}", attempts);
                
                // Add quality score to metadata
                response.Metadata["qualityScore"] = qualityResult.Score;
                response.Metadata["qualityChecks"] = qualityResult.CheckResults;
                
                return response;
            }

            _logger.LogWarning("AI response failed quality validation on attempt {Attempt}. Issues: {Issues}", 
                attempts, string.Join(", ", qualityResult.Issues));

            if (attempts >= maxAttempts)
            {
                _logger.LogError("AI response failed quality validation after {MaxAttempts} attempts", maxAttempts);
                
                return AIResponse.CreateError(
                    $"Response failed quality validation: {string.Join(", ", qualityResult.Issues)}", 
                    response.Duration, 
                    response.ModelUsed);
            }

            // Modify prompt for retry
            prompt = EnhancePromptForRetry(prompt, qualityResult.Issues, attempts);
        }

        return AIResponse.CreateError("Maximum quality retry attempts exceeded", TimeSpan.Zero);
    }

    private string EnhancePromptForRetry(string originalPrompt, List<string> issues, int attempt)
    {
        var enhancement = issues switch
        {
            var list when list.Contains("too_short") => 
                "\n\nPlease provide a more detailed and comprehensive response.",
            
            var list when list.Contains("off_topic") => 
                "\n\nPlease focus specifically on the question asked and avoid tangential information.",
            
            var list when list.Contains("unclear") => 
                "\n\nPlease provide a clear, well-structured response that directly addresses the question.",
            
            var list when list.Contains("inappropriate_tone") => 
                "\n\nPlease use a professional, helpful tone in your response.",
            
            _ => $"\n\nPlease improve the response quality (attempt {attempt + 1})."
        };

        return originalPrompt + enhancement;
    }

    // Delegate other methods...
}

public interface IQualityValidator
{
    Task<QualityValidationResult> ValidateAsync(QualityValidationRequest request);
}

public class QualityValidationRequest
{
    public string Prompt { get; set; } = string.Empty;
    public string Response { get; set; } = string.Empty;
    public Dictionary<string, object> Context { get; set; } = new();
}

public class QualityValidationResult
{
    public bool IsAcceptable { get; set; }
    public double Score { get; set; } // 0.0 to 1.0
    public List<string> Issues { get; set; } = new();
    public Dictionary<string, object> CheckResults { get; set; } = new();
}

public class BasicQualityValidator : IQualityValidator
{
    public Task<QualityValidationResult> ValidateAsync(QualityValidationRequest request)
    {
        var result = new QualityValidationResult { CheckResults = new Dictionary<string, object>() };
        var issues = new List<string>();
        var score = 1.0;

        // Length check
        if (request.Response.Length < 50)
        {
            issues.Add("too_short");
            score -= 0.3;
        }
        result.CheckResults["lengthCheck"] = request.Response.Length;

        // Basic relevance check (simplified)
        var promptWords = request.Prompt.ToLowerInvariant().Split(' ');
        var responseWords = request.Response.ToLowerInvariant().Split(' ');
        var commonWords = promptWords.Intersect(responseWords).Count();
        var relevanceScore = (double)commonWords / promptWords.Length;
        
        if (relevanceScore < 0.1)
        {
            issues.Add("off_topic");
            score -= 0.4;
        }
        result.CheckResults["relevanceScore"] = relevanceScore;

        // Professionalism check (basic)
        var unprofessionalWords = new[] { "stupid", "dumb", "idiotic", "whatever", "dunno" };
        var unprofessionalCount = unprofessionalWords.Count(word => 
            request.Response.ToLowerInvariant().Contains(word));
        
        if (unprofessionalCount > 0)
        {
            issues.Add("inappropriate_tone");
            score -= 0.2;
        }
        result.CheckResults["professionalismCheck"] = unprofessionalCount == 0;

        result.Score = Math.Max(0.0, score);
        result.Issues = issues;
        result.IsAcceptable = score >= 0.6; // Minimum acceptable score

        return Task.FromResult(result);
    }
}

public class QualitySettings
{
    public int MaxRetryAttempts { get; set; } = 3;
    public double MinAcceptableScore { get; set; } = 0.6;
    public bool EnableQualityLogging { get; set; } = true;
}
```

### Fallback Mechanisms
Handle AI service outages gracefully:

```csharp
public class FallbackAIService : IAIService
{
    private readonly List<IAIService> _aiServices;
    private readonly ILogger<FallbackAIService> _logger;
    private readonly FallbackConfiguration _config;
    private int _currentServiceIndex = 0;

    public FallbackAIService(
        List<IAIService> aiServices,
        FallbackConfiguration config,
        ILogger<FallbackAIService> logger)
    {
        _aiServices = aiServices ?? throw new ArgumentNullException(nameof(aiServices));
        _config = config;
        _logger = logger;

        if (!_aiServices.Any())
        {
            throw new ArgumentException("At least one AI service must be provided", nameof(aiServices));
        }
    }

    public async Task<AIResponse> GetCompletionAsync(string prompt, CancellationToken cancellationToken = default)
    {
        var exceptions = new List<Exception>();

        for (int attempt = 0; attempt < _aiServices.Count; attempt++)
        {
            var serviceIndex = (_currentServiceIndex + attempt) % _aiServices.Count;
            var service = _aiServices[serviceIndex];

            try
            {
                _logger.LogDebug("Attempting AI request with service {ServiceIndex} (attempt {Attempt})", 
                    serviceIndex, attempt + 1);

                var response = await service.GetCompletionAsync(prompt, cancellationToken);

                if (response.IsSuccess)
                {
                    // Success! Update primary service if needed
                    if (serviceIndex != _currentServiceIndex)
                    {
                        _logger.LogInformation("Fallback service {ServiceIndex} succeeded, updating primary", serviceIndex);
                        _currentServiceIndex = serviceIndex;
                    }

                    // Add fallback metadata
                    response.Metadata["fallbackAttempt"] = attempt + 1;
                    response.Metadata["serviceIndex"] = serviceIndex;
                    
                    return response;
                }
                else
                {
                    _logger.LogWarning("AI service {ServiceIndex} returned error: {Error}", 
                        serviceIndex, response.ErrorMessage);
                    exceptions.Add(new InvalidOperationException($"Service {serviceIndex}: {response.ErrorMessage}"));
                }
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "AI service {ServiceIndex} threw exception", serviceIndex);
                exceptions.Add(ex);

                // If this was our primary service, mark it as potentially unavailable
                if (serviceIndex == _currentServiceIndex && _config.EnableCircuitBreaker)
                {
                    await ConsiderCircuitBreakerAsync(serviceIndex);
                }
            }
        }

        // All services failed
        _logger.LogError("All AI services failed. Returning error response");
        
        var aggregateException = new AggregateException(exceptions);
        return AIResponse.CreateError(
            $"All AI services failed: {string.Join("; ", exceptions.Select(e => e.Message))}", 
            TimeSpan.Zero);
    }

    private async Task ConsiderCircuitBreakerAsync(int serviceIndex)
    {
        // Simple circuit breaker logic
        // In production, use a proper circuit breaker library
        _logger.LogWarning("Service {ServiceIndex} failing, considering circuit breaker", serviceIndex);
        
        // Switch to next available service
        _currentServiceIndex = (_currentServiceIndex + 1) % _aiServices.Count;
        
        await Task.Delay(TimeSpan.FromSeconds(1)); // Brief delay
    }

    // Delegate other methods to primary service
    public async Task InitializeAsync(AIConfiguration configuration, CancellationToken cancellationToken = default)
    {
        // Initialize all services
        var tasks = _aiServices.Select(service => service.InitializeAsync(configuration, cancellationToken));
        await Task.WhenAll(tasks);
    }

    public async Task<bool> IsConfiguredAsync(CancellationToken cancellationToken = default)
    {
        // Return true if any service is configured
        var tasks = _aiServices.Select(service => service.IsConfiguredAsync(cancellationToken));
        var results = await Task.WhenAll(tasks);
        return results.Any(result => result);
    }

    public async Task<bool> TestConnectionAsync(CancellationToken cancellationToken = default)
    {
        // Test all services and return true if any work
        var tasks = _aiServices.Select(service => service.TestConnectionAsync(cancellationToken));
        var results = await Task.WhenAll(tasks);
        return results.Any(result => result);
    }

    // ... other delegated methods
}

public class FallbackConfiguration
{
    public bool EnableCircuitBreaker { get; set; } = true;
    public TimeSpan CircuitBreakerTimeout { get; set; } = TimeSpan.FromMinutes(5);
    public int MaxFailuresBeforeSwitch { get; set; } = 3;
}

// Usage in DI
public void ConfigureFallbackAI(IServiceCollection services, IConfiguration configuration)
{
    // Configure multiple AI services
    services.Configure<AIConfiguration>("Primary", configuration.GetSection("AI:Primary"));
    services.Configure<AIConfiguration>("Secondary", configuration.GetSection("AI:Secondary"));

    // Register individual services
    services.AddKeyedScoped<IAIService, SemanticKernelAIService>("primary");
    services.AddKeyedScoped<IAIService, SemanticKernelAIService>("secondary");

    // Register fallback service
    services.AddScoped<IAIService>(provider =>
    {
        var primaryService = provider.GetRequiredKeyedService<IAIService>("primary");
        var secondaryService = provider.GetRequiredKeyedService<IAIService>("secondary");
        
        return new FallbackAIService(
            new List<IAIService> { primaryService, secondaryService },
            new FallbackConfiguration(),
            provider.GetRequiredService<ILogger<FallbackAIService>>()
        );
    });
}
```

## Production Configuration Examples

### Azure OpenAI Production Setup
```json
{
  "AI": {
    "Provider": "AzureOpenAI",
    "ModelId": "gpt-4-0613",
    "Endpoint": "https://your-resource.openai.azure.com",
    "ApiKey": "#{AZURE_OPENAI_API_KEY}#",
    "MaxTokens": 4000,
    "Temperature": 0.3,
    "TopP": 0.95,
    "TimeoutSeconds": 60,
    "AdditionalSettings": {
      "ApiVersion": "2024-02-15-preview",
      "RequestRetries": 3,
      "BackoffDelay": "00:00:02"
    }
  },
  "Monitoring": {
    "EnableCostTracking": true,
    "EnableQualityChecks": true,
    "EnablePerformanceMetrics": true
  },
  "Limits": {
    "DailyBudget": 500.00,
    "RequestsPerMinute": 6000,
    "TokensPerMinute": 150000,
    "MaxConcurrentRequests": 20
  }
}
```

### OpenAI Production Setup
```json
{
  "AI": {
    "Provider": "OpenAI",
    "ModelId": "gpt-4-1106-preview",
    "ApiKey": "#{OPENAI_API_KEY}#",
    "MaxTokens": 4000,
    "Temperature": 0.2,
    "TopP": 1.0,
    "TimeoutSeconds": 45,
    "AdditionalSettings": {
      "Organization": "your-org-id",
      "RequestRetries": 2,
      "BackoffDelay": "00:00:01"
    }
  },
  "Monitoring": {
    "EnableCostTracking": true,
    "EnableQualityChecks": true,
    "CostAlertThreshold": 0.8
  },
  "Limits": {
    "DailyBudget": 200.00,
    "RequestsPerMinute": 3500,
    "TokensPerMinute": 90000,
    "MaxConcurrentRequests": 10
  }
}
```

### Multi-Provider Fallback Setup
```json
{
  "AI": {
    "Primary": {
      "Provider": "AzureOpenAI",
      "ModelId": "gpt-4",
      "Endpoint": "https://primary.openai.azure.com",
      "ApiKey": "#{PRIMARY_API_KEY}#"
    },
    "Secondary": {
      "Provider": "OpenAI",
      "ModelId": "gpt-4-turbo-preview",
      "ApiKey": "#{SECONDARY_API_KEY}#"
    },
    "Fallback": {
      "EnableCircuitBreaker": true,
      "CircuitBreakerTimeout": "00:05:00",
      "MaxFailuresBeforeSwitch": 3
    }
  }
}
```

## Next Steps

### Integration with Other Packages
- **Agent.Orchestration** - Coordinate multiple AI agents in complex workflows
- **Agent.Security** - Secure AI service configurations and API key management
- **Agent.Observability** - Monitor AI usage, costs, and performance metrics

### Advanced AI Patterns
- **Fine-tuned Models** - Train custom models for specific use cases
- **Embedding Services** - Semantic search and similarity matching
- **Function Calling** - AI agents that can call external functions
- **Multi-modal AI** - Text, image, and audio processing capabilities

### Enterprise Considerations
- **Compliance & Governance** - Audit trails, data residency, privacy controls
- **Cost Optimization** - Model selection, caching strategies, batch processing
- **Performance Tuning** - Prompt optimization, response caching, load balancing
- **Disaster Recovery** - Multi-region deployments, service redundancy

---

**ðŸŽ¯ You now have production-ready AI integration that scales with your business needs!**

Agent.AI transforms complex AI service integration into simple, reliable, and cost-effective solutions. Whether you're building simple Q&A agents or sophisticated reasoning systems, you have all the tools to deliver consistent, high-quality AI experiences while maintaining control over costs, quality, and performance.